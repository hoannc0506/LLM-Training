{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11469c88-7545-4cc9-b2cb-70c3ac79352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47149f1a-58cd-44cb-9903-939fd8676a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1799e6dd-475b-4526-a9b0-06bb226cdb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_ds_name = 'CarperAI/openai_summarize_tldr'\n",
    "# split = -1\n",
    "split = 1000 # debug\n",
    "n_proc = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f11366d-4365-42c2-8ab6-9971983329a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_train = load_dataset(sft_ds_name, split=f\"train[:{split}]\", num_proc=n_proc)\n",
    "sft_valid = load_dataset(sft_ds_name, split=f\"valid[:{split}]\", num_proc=n_proc)\n",
    "sft_test = load_dataset(sft_ds_name, split=f\"test[:{split}]\", num_proc=n_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec1e6f-19ed-44a2-b35a-d7e9d8b3bf89",
   "metadata": {},
   "source": [
    "## Format training data\n",
    "- Sumarization task: `###Text: document\\n ### (Short) Summary: summary` -> can customize for different task\n",
    "- Chatbot template: \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75811e7d-1d30-4bd5-90ab-e05de7ed12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"### Text: {example['prompt']}\\n ### Summary: {example['label']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d447d73-8897-429e-939a-4725b6095122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Text: SUBREDDIT: r/relationships\n",
      "TITLE: I (f/22) have to figure out if I want to still know these girls or not and would hate to sound insulting\n",
      "POST: Not sure if this belongs here but it's worth a try. \n",
      "\n",
      "Backstory:\n",
      "When I (f/22) went through my first real breakup 2 years ago because he needed space after a year of dating roand  it effected me more than I thought. It was a horrible time in my life due to living with my mother and finally having the chance to cut her out of my life. I can admit because of it was an emotional wreck and this guy was stable and didn't know how to deal with me. We ended by him avoiding for a month or so after going to a festival with my friends. When I think back I wish he just ended. So after he ended it added my depression I suffered but my friends helped me through it and I got rid of everything from him along with cutting contact. \n",
      "\n",
      "Now: Its been almost 3 years now and I've gotten better after counselling and mild anti depressants. My mother has been out of my life since then so there's been alot of progress. Being stronger after learning some lessons there been more insight about that time of my life but when I see him or a picture everything comes back. The emotions and memories bring me back down. \n",
      "\n",
      "His friends (both girls) are on my facebook because we get along well which is hard to find and I know they'll always have his back. But seeing him in a picture or talking to him at a convention having a conversation is tough. Crying confront of my current boyfriend is something I want to avoid. \n",
      "\n",
      "So I've been thinking that I have to cut contact with these girls because it's time to move on because it's healthier. It's best to avoid him as well. But will they be insulted? Will they accept it? Is there going to be awkwardness? I'm not sure if it's the right to do and could use some outside opinions.\n",
      "TL;DR: \n",
      " ### Summary: I still have contact with an old ex's friends but can't stand to see or talk to him. His friends are really nice ,so how do I tell them I possibly want to unfriend them on Facebook because of him?\n"
     ]
    }
   ],
   "source": [
    "for example in sft_train:\n",
    "    print(formatting_func(example))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7c45e-e7af-4206-afb5-8e8d5c6035fb",
   "metadata": {},
   "source": [
    "## Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba3a10f1-56c2-4b19-b1e2-48c3150338cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0c518f047d43d9be652ee06fea2ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924e94b65fd8418bb0f0757dcd18388c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4f1323b2a14ebbaeb8be4f7ee82493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb3b658ee3f4858b419355724ef924a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa4d3eb9290431dab01fdacd311cc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from trl import ModelConfig, get_quantization_config, get_kbit_device_map\n",
    "from transformers import AutoTokenizer  # Importing AutoTokenizer from transformers\n",
    "\n",
    "# Initializing ModelConfig with the provided model name or path\n",
    "model_config = ModelConfig(\n",
    "    model_name_or_path='facebook/opt-350m'\n",
    ")\n",
    "\n",
    "# Checking the torch_dtype in the model_config and setting it accordingly\n",
    "torch_dtype = (\n",
    "    model_config.torch_dtype\n",
    "    if model_config.torch_dtype in [\"auto\", None]\n",
    "    else getattr(torch, model_config.torch_dtype)\n",
    ")\n",
    "\n",
    "# Getting quantization configuration based on the model_config\n",
    "quantization_config = get_quantization_config(model_config)\n",
    "\n",
    "# Creating model_kwargs dictionary with various model configuration parameters\n",
    "model_kwargs = dict(\n",
    "    revision=model_config.model_revision,\n",
    "    trust_remote_code=model_config.trust_remote_code,\n",
    "    attn_implementation=model_config.attn_implementation,\n",
    "    torch_dtype=torch_dtype,\n",
    "    use_cache=False,\n",
    "    device_map=get_kbit_device_map() if quantization_config is not None else None,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "# Initializing the tokenizer from the pretrained model, using fast tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_config.model_name_or_path, use_fast=True)\n",
    "\n",
    "# Setting pad_token of the tokenizer to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Setting pad_token_id of the tokenizer to eos_token_id\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3fe76d2-7341-42b8-8f3f-ba51ad92e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a371319f-973b-4619-bebf-438ed2fb73a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d1f9538ae4814a162c1e6157f8657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    if isinstance(eval_preds, tuple):\n",
    "        eval_preds = eval_preds[0]\n",
    "    labels_ids = eval_preds.label_ids # list summarization ids\n",
    "    pred_ids = eval_preds.predictions # list predict ids\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    result = rouge.compute(predictions=pred_str, references=label_str)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02599945-3363-4211-95a7-044a68660c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 1 # 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./save_model',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.95,\n",
    "    num_train_epochs=num_epochs,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "300a6cdc-42ee-42d2-9bb6-b1297f77f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a706bf36f054f03815b59339c9939b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bf7a851541496480f9205f4eba4725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13b689cc4774998b6caf9bbcc74795c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7f6308cf9a4011b490388e4dc494a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_input_length = 512\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model_config.model_name_or_path, # name\n",
    "    model_init_kwargs=model_kwargs, \n",
    "    args=training_args,\n",
    "    train_dataset=sft_train,\n",
    "    eval_dataset=sft_valid,\n",
    "    max_seq_length=max_input_length,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    compute_metrics=compute_metrics,\n",
    "    packing=True,\n",
    "    formatting_func=formatting_func # run format first to build dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544cb9f-b20a-4af7-9371-963d69a8aea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5e575c0-7a34-4201-9ef0-061a6c862b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig(model_name_or_path='facebook/opt-350m', model_revision='main', torch_dtype=None, trust_remote_code=False, attn_implementation=None, use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26072327-ed0f-4b30-8cd7-0f281126738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddab71c-24e7-434c-bddf-ff5938f184da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
